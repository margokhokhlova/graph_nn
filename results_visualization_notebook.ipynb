{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"The base file for loading default datasets.\"\"\"\n",
    "import os\n",
    "import math\n",
    "import matplotlib\n",
    "matplotlib.use('tkagg')\n",
    "try:\n",
    "    # Python 2\n",
    "    from urllib2 import HTTPError\n",
    "    from urllib2 import urlopen\n",
    "except ImportError:\n",
    "    # Python 3+\n",
    "    from urllib.error import HTTPError\n",
    "    from urllib.request import urlopen\n",
    "\n",
    "import collections\n",
    "import argparse\n",
    "from data_loader_siamese import *\n",
    "from knn_check import knn_distance_calculation, map_for_dataset\n",
    "from index import BagOfNodesIndex\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.utils import Bunch\n",
    "\n",
    "import networkx as nx\n",
    "global symmetric_dataset\n",
    "symmetric_dataset =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def read_data(\n",
    "        name,\n",
    "        with_classes=True,\n",
    "        prefer_attr_nodes=False,\n",
    "        prefer_attr_edges=False,\n",
    "        produce_labels_nodes=False,\n",
    "        as_graphs=False,\n",
    "        is_symmetric=symmetric_dataset, path = None):\n",
    "    \"\"\"Create a dataset iterable for GraphKernel.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    name : str\n",
    "        The dataset name.\n",
    "\n",
    "    with_classes : bool, default=False\n",
    "        Return an iterable of class labels based on the enumeration.\n",
    "\n",
    "    produce_labels_nodes : bool, default=False\n",
    "        Produce labels for nodes if not found.\n",
    "        Currently this means labeling its node by its degree inside the Graph.\n",
    "        This operation is applied only if node labels are non existent.\n",
    "\n",
    "    prefer_attr_nodes : bool, default=False\n",
    "        If a dataset has both *node* labels and *node* attributes\n",
    "        set as labels for the graph object for *nodes* the attributes.\n",
    "\n",
    "    prefer_attr_edges : bool, default=False\n",
    "        If a dataset has both *edge* labels and *edge* attributes\n",
    "        set as labels for the graph object for *edge* the attributes.\n",
    "\n",
    "    as_graphs : bool, default=False\n",
    "        Return data as a list of Graph Objects.\n",
    "\n",
    "    is_symmetric : bool, default=False\n",
    "        Defines if the graph data describe a symmetric graph.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Gs : iterable\n",
    "        An iterable of graphs consisting of a dictionary, node\n",
    "        labels and edge labels for each graph.\n",
    "\n",
    "    classes : np.array, case_of_appearance=with_classes==True\n",
    "        An one dimensional array of graph classes aligned with the lines\n",
    "        of the `Gs` iterable. Useful for classification.\n",
    "\n",
    "    \"\"\"\n",
    "    indicator_path = path+str(name)+\"_graph_indicator.txt\"\n",
    "    edges_path =  path + \"/\" + str(name) + \"_A.txt\"\n",
    "    node_labels_path = path + \"/\" + str(name) + \"_node_labels.txt\"\n",
    "    node_attributes_path = path +\"/\"+str(name)+\"_node_attributes.txt\"\n",
    "    edge_labels_path = path + \"/\" + str(name) + \"_edge_labels.txt\"\n",
    "    edge_attributes_path = \\\n",
    "        path + \"/\" + str(name) + \"_edge_attributes.txt\"\n",
    "    graph_classes_path = \\\n",
    "        path + \"/\" + str(name) + \"_graph_labels.txt\"\n",
    "\n",
    "    # node graph correspondence\n",
    "    ngc = dict()\n",
    "    # edge line correspondence\n",
    "    elc = dict()\n",
    "    # dictionary that keeps sets of edges\n",
    "    Graphs = dict()\n",
    "    # dictionary of labels for nodes\n",
    "    node_labels = dict()\n",
    "    # dictionary of labels for edges\n",
    "    edge_labels = dict()\n",
    "\n",
    "    # Associate graphs nodes with indexes\n",
    "    with open(indicator_path, \"r\") as f:\n",
    "        for (i, line) in enumerate(f, 1):\n",
    "            ngc[i] = int(line[:-1])\n",
    "            if int(line[:-1]) not in Graphs:\n",
    "                Graphs[int(line[:-1])] = set()\n",
    "            if int(line[:-1]) not in node_labels:\n",
    "                node_labels[int(line[:-1])] = dict()\n",
    "            if int(line[:-1]) not in edge_labels:\n",
    "                edge_labels[int(line[:-1])] = dict()\n",
    "\n",
    "    # Create backwards configuration\n",
    "    graph_node_correspondence = collections.defaultdict(list)\n",
    "    for node in range(len(ngc)):\n",
    "        graph_node_correspondence[ngc[node+1]].append(node+1)\n",
    "\n",
    "\n",
    "    # Extract graph edges\n",
    "    with open(edges_path, \"r\") as f:\n",
    "        for (i, line) in enumerate(f, 1):\n",
    "            edge = line[:-1].replace(' ', '').split(\",\")\n",
    "            elc[i] = (int(edge[0]), int(edge[1]))\n",
    "            Graphs[ngc[int(edge[0])]].add((int(edge[0]), int(edge[1])))\n",
    "            if is_symmetric:\n",
    "                Graphs[ngc[int(edge[1])]].add((int(edge[1]), int(edge[0])))\n",
    "\n",
    "    # Extract node attributes\n",
    "    if prefer_attr_nodes:\n",
    "        with open(node_attributes_path, \"r\") as f:\n",
    "            for (i, line) in enumerate(f, 1):\n",
    "                node_labels[ngc[i]][i] = \\\n",
    "                    [float(num) for num in\n",
    "                     line[:-1].replace(' ', '').split(\",\")]\n",
    "                #if np.isnan(node_labels[ngc[i]][i]).any():  # then there are None values\n",
    "                node_labels[ngc[i]][i] = [0.00 if math.isnan(x) else x for x in node_labels[ngc[i]][i]][:]  # remove NaNs and take only 3 first\n",
    "\n",
    "                #node_labels[ngc[i]][i] = [x for x in node_labels[ngc[i]][i][1:2]]  # remove NaNs\n",
    "    # Extract node labels\n",
    "    elif not produce_labels_nodes:\n",
    "        with open(node_labels_path, \"r\") as f:\n",
    "            for (i, line) in enumerate(f, 1):\n",
    "                node_labels[ngc[i]][i] = int(line[:-1])\n",
    "    elif produce_labels_nodes:\n",
    "        for i in range(1, len(Graphs)+1):\n",
    "            node_labels[i] = dict(Counter(s for (s, d) in Graphs[i] if s != d))\n",
    "            if not bool(node_labels[i]): #if labels are empty\n",
    "                node_labels[i] = {s:0 for s in graph_node_correspondence[i]}\n",
    "\n",
    "    # Extract edge attributes\n",
    "    if prefer_attr_edges:\n",
    "        with open(edge_attributes_path, \"r\") as f:\n",
    "            for (i, line) in enumerate(f, 1):\n",
    "                attrs = [float(num)\n",
    "                         for num in line[:-1].replace(' ', '').split(\",\")]\n",
    "                edge_labels[ngc[elc[i][0]]][elc[i]] = attrs\n",
    "                if is_symmetric:\n",
    "                    edge_labels[ngc[elc[i][1]]][(elc[i][1], elc[i][0])] = attrs\n",
    "\n",
    "    # Extract edge labels\n",
    "    elif not prefer_attr_edges and  os.path.exists(edge_labels_path):\n",
    "        with open(edge_labels_path, \"r\") as f:\n",
    "            for (i, line) in enumerate(f, 1):\n",
    "                edge_labels[ngc[elc[i][0]]][elc[i]] = float(line[:-1])\n",
    "                if is_symmetric:\n",
    "                    edge_labels[ngc[elc[i][1]]][(elc[i][1], elc[i][0])] = \\\n",
    "                        float(line[:-1])\n",
    "    elif not prefer_attr_edges and  not os.path.exists(edge_labels_path):\n",
    "        with open(edges_path, \"r\") as f:\n",
    "            for (i, line) in enumerate(f, 1):\n",
    "                edge_labels[ngc[elc[i][0]]][elc[i]] = 1\n",
    "                if is_symmetric:\n",
    "                    edge_labels[ngc[elc[i][1]]][(elc[i][1], elc[i][0])] = 1\n",
    "\n",
    "    Gs = list()\n",
    "    if as_graphs:\n",
    "        for i in range(1, len(Graphs)+1):\n",
    "            nx_graph = nx.Graph()\n",
    "            #nx_graph.add_nodes_from(Graphs[i])\n",
    "            nx_graph.add_edges_from(edge_labels[i])\n",
    "            nx.set_node_attributes(nx_graph, node_labels[i], 'labels')\n",
    "            Gs.append(nx_graph)\n",
    "    else:\n",
    "        for i in range(1, len(Graphs)+1):\n",
    "            Gs.append([Graphs[i], node_labels[i], edge_labels[i]])\n",
    "\n",
    "    if with_classes:\n",
    "        classes = []\n",
    "        with open(graph_classes_path, \"r\") as f:\n",
    "            for line in f:\n",
    "                classes.append(int(line[:-1])-1)\n",
    "\n",
    "        classes = np.array(classes, dtype=np.int)\n",
    "        return Bunch(data=Gs, target=classes)\n",
    "    else:\n",
    "        return Bunch(data=Gs)\n",
    "\n",
    "\n",
    "\n",
    "def visualize_matches(index, knn_matches, gt19, dataset04, dataset19):\n",
    "    ''' a quick function to visualize the graphs\n",
    "    index - the index of the mathcing query int\n",
    "    knn_matches  - returned most similar graphs (labels) [[]]\n",
    "    gt19 - GT correspondences []\n",
    "    datasets - datasets with nx graphs to display the result - custom class'''\n",
    "    query_result = knn_matches[index]\n",
    "    query_gt = gt19[index]\n",
    "    # find the graphs which correspond to queris and GT and display them\n",
    "    query_graph_index = np.where(dataset19.target==query_gt)[0][0] #take only one graph as a demo\n",
    "    graph_query = dataset19.data[query_graph_index]\n",
    "    fig, axs = plt.subplots(1, 6,figsize=(18, 10))\n",
    "    nx.draw(graph_query, with_labels=True, ax=axs[0])\n",
    "    axs[0].set_title(f\"Query graph, gt {query_gt}\")\n",
    "    for i in range(1,len(query_result)+1):\n",
    "        nx.draw(dataset04.data[np.where(dataset04.target==query_result[i-1])[0][0]], with_labels=True, ax=axs[i])\n",
    "        axs[i].set_title(f\"gt {query_result[i-1]}\")\n",
    "    fig.suptitle('Returned KNN-matches')\n",
    "    plt.show()\n",
    "\n",
    "def cross_val_map_local(data04, data19, dims=17):\n",
    "    features04 = np.empty((0, dims))\n",
    "    features19 = np.empty((0, dims))\n",
    "    gt04 = []\n",
    "    gt19 = []\n",
    "    dist_graphs_19 = []  #to store the distinct graphs\n",
    "    for i in range(len(data19.data['features_onehot'])):\n",
    "        gt19 += [data19.data['targets'][i]] * len(data19.data['features_onehot'][i])\n",
    "        features19 = np.vstack((features19, data19.data['features_onehot'][i]))\n",
    "        dist_graphs_19 += [i] * len(data19.data['features_onehot'][i])\n",
    "    dist_graphs_04 = []  # to store the distinct graphs\n",
    "    for i in range(len(data04.data['features_onehot'])):\n",
    "        gt04 += [data04.data['targets'][i]] * len(data04.data['features_onehot'][i])\n",
    "        features04 = np.vstack((features04, data04.data['features_onehot'][i]))\n",
    "        dist_graphs_04 += [i] * len(data04.data['features_onehot'][i])\n",
    "    indexer = BagOfNodesIndex(dimension=features04.shape[1], N_CENTROIDS=128)\n",
    "    indexer.train(features04, dist_graphs_04)\n",
    "    unique_graphs = np.unique(dist_graphs_19)\n",
    "    gt_gt19 = build_gt_voc(dist_graphs_19, gt19)\n",
    "    gt_gt04 = build_gt_voc(dist_graphs_04, gt04)\n",
    "    gt_19 = []\n",
    "    knn_array = []\n",
    "    for i in unique_graphs:\n",
    "        query_features = features19[dist_graphs_19 == i]\n",
    "        answer = indexer.search(query_features)\n",
    "        sorted(answer, key=lambda x: x[1], reverse=True)  # sort the array\n",
    "        gt_19.append(gt_gt19[i])\n",
    "        knn_array.append([gt_gt04[a] for a in answer[0][:args.N]])  # workaround for structure\n",
    "\n",
    "    map = map_for_dataset(gt_19, knn_array)\n",
    "    return map, knn_array, gt_19\n",
    "\n",
    "def build_gt_voc(unique_graphs, gt):\n",
    "    ''' return a vocabulary matching gt zone labes with graph labels'''\n",
    "    gt_g = {}\n",
    "    for i in range(len(unique_graphs)):\n",
    "        if unique_graphs[i] not in gt_g:\n",
    "            gt_g[unique_graphs[i]] = gt[i]\n",
    "    return gt_g"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "first_dataset='ign_2004'\n",
    "test_dataset='ign_2019'\n",
    "batch_size=50\n",
    "n_folds=1\n",
    "N=5\n",
    "\n",
    "# datareader19 = DataReader(data_dir='./data/IGN_all_clean/%s/' % args.first_dataset.upper(),\n",
    "#                           rnd_state=np.random.RandomState(args.seed),\n",
    "#                           folds=args.n_folds,\n",
    "#                           use_cont_node_attr=True)\n",
    "#\n",
    "# datareader10 = DataReader(data_dir='./data/IGN_all_clean/%s/' % args.test_dataset.upper(),\n",
    "#                           rnd_state=np.random.RandomState(args.seed),\n",
    "#                           folds=args.n_folds,\n",
    "#                           use_cont_node_attr=True)\n",
    "\n",
    "# start = time.time()\n",
    "# map, knn, gt = cross_val_map_local(datareader19, datareader10)\n",
    "# print(map)\n",
    "# end = time.time()\n",
    "# print('final map@N is %f time to query all files %f seconds.' % (map, end - start))\n",
    "# print('it gives %f sec per query' % ((end - start) / len(datareader19.data['targets'])))\n",
    "\n",
    "\n",
    "    ## visualization part based on the KNN results\n",
    "\n",
    "\n",
    "IGN19 = read_data('IGN04', #TODO fix this to make automatic\n",
    "                  with_classes=True,\n",
    "                  prefer_attr_nodes=True,\n",
    "                  prefer_attr_edges=False,\n",
    "                  produce_labels_nodes=False,\n",
    "                  as_graphs=True,\n",
    "                  is_symmetric=symmetric_dataset,\n",
    "                  path='./data/IGN_all_clean/%s/'% first_dataset.upper())\n",
    "\n",
    "IGN10 = read_data('IGN19',\n",
    "                  with_classes=True,\n",
    "                  prefer_attr_nodes=True,\n",
    "                  prefer_attr_edges=False,\n",
    "                  produce_labels_nodes=False,\n",
    "                  as_graphs=True,\n",
    "                  is_symmetric=symmetric_dataset,\n",
    "                  path='./data/IGN_all_clean/%s/' % test_dataset.upper())\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "knn_matches = [[3846, 3949, 4012, 2323, 3891], [1939, 1503, 184, 4611, 5917], [3593, 200, 5956, 1290, 2476], [3983, 3447, 3725, 3569, 5940], [2402, 749, 2446, 2667, 541], [2548, 5868, 1670, 1164, 1664], [1085, 20, 2506, 3701, 2041], [1753, 3947, 3106, 3919, 3122], [4604, 297, 2024, 5305, 4763], [4086, 2738, 2679, 2762, 2527]]\n",
    "gt19 = [2406, 654, 3593, 172, 2774, 4987, 1085, 4365, 5888, 2738]\n",
    "# now just go through the KNN and display the returned values and a true corresponding graph\n",
    "visualize_matches(0, knn_matches,gt19, IGN19, IGN10)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}