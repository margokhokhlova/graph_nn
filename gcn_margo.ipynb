{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import math\n",
    "import torch\n",
    "import torch.utils\n",
    "import torch.utils.data\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from torch.nn.parameter import Parameter\n",
    "from os.path import join as pjoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment parameters\n",
    "batch_size = 32\n",
    "threads = 0\n",
    "lr = 0.005\n",
    "epochs = 40\n",
    "log_interval = 10\n",
    "wdecay = 1e-4\n",
    "emb_dim = 128 # I am trying to get an embedding in the end\n",
    "dataset = 'ign_2004'\n",
    "dataset2 = 'ign_2019'\n",
    "model_name = 'gcn'  # 'gcn', 'unet'\n",
    "device = 'cpu'  # 'cuda', 'cpu'\n",
    "visualize = True\n",
    "shuffle_nodes = False\n",
    "n_folds = 10  # 10-fold cross validation\n",
    "seed = 111\n",
    "print('torch', torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loader and reader\n",
    "class GraphDataSiamese(torch.utils.data.Dataset):\n",
    "    def __init__(self,\n",
    "                 datareader04, datareader19,\n",
    "                 fold_id,\n",
    "                 split):\n",
    "        self.fold_id = fold_id\n",
    "        self.split = split\n",
    "        self.rnd_state = datareader.rnd_state\n",
    "        self.set_fold(datareader04.data, datareader19.data, fold_id)\n",
    "\n",
    "    def set_fold(self, data04, data19, fold_id):\n",
    "        self.total = len(data04['targets'])\n",
    "        self.N_nodes_max =max(data04['N_nodes_max'], data19['N_nodes_max'])\n",
    "        self.n_classes = data04['n_classes']\n",
    "        self.features_dim = data04['features_dim']\n",
    "        self.idx = data04['splits'][fold_id][self.split]\n",
    "        # use deepcopy to make sure we don't alter objects in folds\n",
    "        #for 2004\n",
    "        self.labels04 = copy.deepcopy([data04['targets'][i] for i in self.idx])\n",
    "        self.adj_list04 = copy.deepcopy([data04['adj_list'][i] for i in self.idx])\n",
    "        self.features_onehot04 = copy.deepcopy([data04['features_onehot'][i] for i in self.idx])\n",
    "        print('%s: %d/%d' % (self.split.upper(), len(self.labels04), len(data04['targets'])))\n",
    "        self.indices = np.arange(len(self.idx))  # sample indices for this epoch\n",
    "        #for 2019\n",
    "        self.labels19 = copy.deepcopy([data19['targets'][i] for i in self.idx])\n",
    "        self.adj_list19 = copy.deepcopy([data19['adj_list'][i] for i in self.idx])\n",
    "        self.features_onehot19 = copy.deepcopy([data19['features_onehot'][i] for i in self.idx])\n",
    "\n",
    "\n",
    "    def pad(self, mtx, desired_dim1, desired_dim2=None, value=0):\n",
    "        sz = mtx.shape\n",
    "        assert len(sz) == 2, ('only 2d arrays are supported', sz)\n",
    "        # if np.all(np.array(sz) < desired_dim1 / 3): print('matrix shape is suspiciously small', sz, desired_dim1)\n",
    "        if desired_dim2 is not None:\n",
    "            mtx = np.pad(mtx, ((0, desired_dim1 - sz[0]), (0, desired_dim2 - sz[1])), 'constant', constant_values=value)\n",
    "        else:\n",
    "            mtx = np.pad(mtx, ((0, desired_dim1 - sz[0]), (0, 0)), 'constant', constant_values=value)\n",
    "        return mtx\n",
    "\n",
    "    def nested_list_to_torch(self, data):\n",
    "        if isinstance(data, dict):\n",
    "            keys = list(data.keys())\n",
    "        for i in range(len(data)):\n",
    "            if isinstance(data, dict):\n",
    "                i = keys[i]\n",
    "            if isinstance(data[i], np.ndarray):\n",
    "                data[i] = torch.from_numpy(data[i]).float()\n",
    "            elif isinstance(data[i], list):\n",
    "                data[i] = list_to_torch(data[i])\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels04)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        index = self.indices[index]\n",
    "        N_nodes_max = self.N_nodes_max\n",
    "        #04\n",
    "        N_nodes_04 = self.adj_list04[index].shape[0]\n",
    "        graph_support_04 = np.zeros(self.N_nodes_max)\n",
    "        graph_support_04[:N_nodes_04] = 1\n",
    "        #19\n",
    "        N_nodes_19 = self.adj_list19[index].shape[0]\n",
    "        graph_support_19 = np.zeros(self.N_nodes_max)\n",
    "        graph_support_19[:N_nodes_19] = 1\n",
    "\n",
    "        return self.nested_list_to_torch(\n",
    "            [self.pad(self.features_onehot04[index].copy(), self.N_nodes_max),  # node_features\n",
    "             self.pad(self.adj_list04[index], self.N_nodes_max, self.N_nodes_max),  # adjacency matrix\n",
    "             graph_support_04,  # mask with values of 0 for dummy (zero padded) nodes, otherwise 1\n",
    "             N_nodes_04,\n",
    "             int(self.labels04[index])]), self.nested_list_to_torch(\n",
    "            [self.pad(self.features_onehot19[index].copy(), self.N_nodes_max),  # node_features\n",
    "             self.pad(self.adj_list19[index], self.N_nodes_max, self.N_nodes_max),  # adjacency matrix\n",
    "             graph_support_19,  # mask with values of 0 for dummy (zero padded) nodes, otherwise 1\n",
    "             N_nodes_19,\n",
    "             int(self.labels19[index])]) # convert to torch\n",
    "\n",
    "\n",
    "class DataReader():\n",
    "    '''\n",
    "    Class to read the txt files containing all data of the dataset\n",
    "    '''\n",
    "\n",
    "    def __init__(self,\n",
    "                 data_dir,  # folder with txt files\n",
    "                 rnd_state=None,\n",
    "                 use_cont_node_attr=False,\n",
    "                 # use or not additional float valued node attributes available in some datasets\n",
    "                 folds=10):\n",
    "\n",
    "        self.data_dir = data_dir\n",
    "        self.rnd_state = np.random.RandomState() if rnd_state is None else rnd_state\n",
    "        self.use_cont_node_attr = use_cont_node_attr\n",
    "        files = os.listdir(self.data_dir)\n",
    "        data = {}\n",
    "        nodes, graphs = self.read_graph_nodes_relations(\n",
    "            list(filter(lambda f: f.find('graph_indicator') >= 0, files))[0])\n",
    "        data['features'] = self.read_node_features(list(filter(lambda f: f.find('node_labels') >= 0, files))[0],\n",
    "                                                   nodes, graphs, fn=lambda s: int(s.strip()))\n",
    "        data['adj_list'] = self.read_graph_adj(list(filter(lambda f: f.find('_A') >= 0, files))[0], nodes, graphs)\n",
    "        data['targets'] = np.array(self.parse_txt_file(list(filter(lambda f: f.find('graph_labels') >= 0, files))[0],\n",
    "                                                       line_parse_fn=lambda s: int(float(s.strip()))))\n",
    "\n",
    "        if self.use_cont_node_attr:\n",
    "            data['attr'] = self.read_node_features(list(filter(lambda f: f.find('node_attributes') >= 0, files))[0],\n",
    "                                                   nodes, graphs,\n",
    "                                                   fn=lambda s: np.array(list(map(float, s.strip().split(',')))))\n",
    "\n",
    "        features, n_edges, degrees = [], [], []\n",
    "        for sample_id, adj in enumerate(data['adj_list']):\n",
    "            N = len(adj)  # number of nodes\n",
    "            if data['features'] is not None:\n",
    "                assert N == len(data['features'][sample_id]), (N, len(data['features'][sample_id]))\n",
    "            n = np.sum(adj)  # total sum of edges\n",
    "            assert n % 2 == 0, n\n",
    "            n_edges.append(int(n/2))  # undirected edges, so need to divide by 2 n_edges.append(int(n/2))\n",
    "            if not np.allclose(adj, adj.T):\n",
    "                print(sample_id, 'not symmetric')\n",
    "            degrees.extend(list(np.sum(adj, 1)))\n",
    "            features.append(np.array(data['features'][sample_id]))\n",
    "\n",
    "        # Create features over graphs as one-hot vectors for each node\n",
    "        features_all = np.concatenate(features)\n",
    "        features_min = features_all.min()\n",
    "        features_dim = int(features_all.max() - features_min + 1)  # number of possible values\n",
    "\n",
    "        features_onehot = []\n",
    "        for i, x in enumerate(features):\n",
    "            feature_onehot = np.zeros((len(x), features_dim))\n",
    "            for node, value in enumerate(x):\n",
    "                feature_onehot[node, value - features_min] = 1\n",
    "            if self.use_cont_node_attr:\n",
    "                feature_onehot = np.concatenate((feature_onehot, np.array(data['attr'][i])), axis=1)\n",
    "            features_onehot.append(feature_onehot)\n",
    "\n",
    "        if self.use_cont_node_attr:\n",
    "            features_dim = features_onehot[0].shape[1]\n",
    "\n",
    "        shapes = [len(adj) for adj in data['adj_list']]\n",
    "        labels = data['targets']  # graph class labels\n",
    "        labels -= np.min(labels)  # to start from 0\n",
    "        N_nodes_max = np.max(shapes)\n",
    "\n",
    "        classes = np.unique(labels)\n",
    "        n_classes = len(classes)\n",
    "\n",
    "        if not np.all(np.diff(classes) == 1):\n",
    "            print('making labels sequential, otherwise pytorch might crash')\n",
    "            labels_new = np.zeros(labels.shape, dtype=labels.dtype) - 1\n",
    "            for lbl in range(n_classes):\n",
    "                labels_new[labels == classes[lbl]] = lbl\n",
    "            labels = labels_new\n",
    "            classes = np.unique(labels)\n",
    "            assert len(np.unique(labels)) == n_classes, np.unique(labels)\n",
    "\n",
    "        print('N nodes avg/std/min/max: \\t%.2f/%.2f/%d/%d' % (\n",
    "        np.mean(shapes), np.std(shapes), np.min(shapes), np.max(shapes)))\n",
    "        print('N edges avg/std/min/max: \\t%.2f/%.2f/%d/%d' % (\n",
    "        np.mean(n_edges), np.std(n_edges), np.min(n_edges), np.max(n_edges)))\n",
    "        print('Node degree avg/std/min/max: \\t%.2f/%.2f/%d/%d' % (\n",
    "        np.mean(degrees), np.std(degrees), np.min(degrees), np.max(degrees)))\n",
    "        print('Node features dim: \\t\\t%d' % features_dim)\n",
    "        print('N classes: \\t\\t\\t%d' % n_classes)\n",
    "        print('Classes: \\t\\t\\t%s' % str(classes))\n",
    "        #for lbl in classes:\n",
    "        #    print('Class %d: \\t\\t\\t%d samples' % (lbl, np.sum(labels == lbl)))\n",
    "\n",
    "        for u in np.unique(features_all):\n",
    "            print('feature {}, count {}/{}'.format(u, np.count_nonzero(features_all == u), len(features_all)))\n",
    "\n",
    "        N_graphs = len(labels)  # number of samples (graphs) in data\n",
    "        assert N_graphs == len(data['adj_list']) == len(features_onehot), 'invalid data'\n",
    "\n",
    "        # Create test sets first\n",
    "        train_ids, test_ids = self.split_ids(np.arange(N_graphs), rnd_state=self.rnd_state, folds=folds)\n",
    "\n",
    "        # Create train sets\n",
    "        splits = []\n",
    "        for fold in range(folds):\n",
    "            splits.append({'train': train_ids[fold],\n",
    "                           'test': test_ids[fold]})\n",
    "\n",
    "        data['features_onehot'] = features_onehot\n",
    "        data['targets'] = labels\n",
    "        data['splits'] = splits\n",
    "        data['N_nodes_max'] = np.max(shapes)  # max number of nodes\n",
    "        data['features_dim'] = features_dim\n",
    "        data['n_classes'] = n_classes\n",
    "\n",
    "        self.data = data\n",
    "\n",
    "    def split_ids(self, ids_all, rnd_state=None, folds=10):\n",
    "        n = len(ids_all)\n",
    "        ids = ids_all[rnd_state.permutation(n)]\n",
    "        stride = int(np.ceil(n / float(folds)))\n",
    "        test_ids = [ids[i: i + stride] for i in range(0, n, stride)]\n",
    "        assert np.all(\n",
    "            np.unique(np.concatenate(test_ids)) == sorted(ids_all)), 'some graphs are missing in the test sets'\n",
    "        assert len(test_ids) == folds, 'invalid test sets'\n",
    "        train_ids = []\n",
    "        for fold in range(folds):\n",
    "            train_ids.append(np.array([e for e in ids if e not in test_ids[fold]]))\n",
    "            assert len(train_ids[fold]) + len(test_ids[fold]) == len(\n",
    "                np.unique(list(train_ids[fold]) + list(test_ids[fold]))) == n, 'invalid splits'\n",
    "\n",
    "        return train_ids, test_ids\n",
    "\n",
    "    def parse_txt_file(self, fpath, line_parse_fn=None):\n",
    "        with open(pjoin(self.data_dir, fpath), 'r') as f:\n",
    "            lines = f.readlines()\n",
    "        data = [line_parse_fn(s) if line_parse_fn is not None else s for s in lines]\n",
    "        return data\n",
    "\n",
    "    def read_graph_adj(self, fpath, nodes, graphs):\n",
    "        edges = self.parse_txt_file(fpath, line_parse_fn=lambda s: s.split(','))\n",
    "        adj_dict = {}\n",
    "        for edge in edges:\n",
    "            node1 = int(edge[0].strip()) -1 # -1 because of zero-indexing in our code\n",
    "            node2 = int(edge[1].strip()) -1\n",
    "            graph_id = nodes[node1]\n",
    "            assert graph_id == nodes[node2], ('invalid data', graph_id, nodes[node2])\n",
    "            if graph_id not in adj_dict:\n",
    "                n = len(graphs[graph_id])\n",
    "                adj_dict[graph_id] = np.zeros((n, n))\n",
    "            ind1 = np.where(graphs[graph_id] == node1)[0]\n",
    "            ind2 = np.where(graphs[graph_id] == node2)[0]\n",
    "            assert len(ind1) == len(ind2) == 1, (ind1, ind2)\n",
    "            adj_dict[graph_id][ind1, ind2] = 1\n",
    "            adj_dict[graph_id][ind2,ind1] = 1 # Modified to make my data symmetric - > to remove for other datasets\n",
    "\n",
    "        adj_list = [adj_dict[graph_id] for graph_id in sorted(list(graphs.keys()))]\n",
    "\n",
    "        return adj_list\n",
    "\n",
    "    def read_graph_nodes_relations(self, fpath):\n",
    "        graph_ids = self.parse_txt_file(fpath, line_parse_fn=lambda s: int(s.rstrip()))\n",
    "        nodes, graphs = {}, {}\n",
    "        for node_id, graph_id in enumerate(graph_ids):\n",
    "            if graph_id not in graphs:\n",
    "                graphs[graph_id] = []\n",
    "            graphs[graph_id].append(node_id)\n",
    "            nodes[node_id] = graph_id\n",
    "        graph_ids = np.unique(list(graphs.keys()))\n",
    "        for graph_id in graphs:\n",
    "            graphs[graph_id] = np.array(graphs[graph_id])\n",
    "        return nodes, graphs\n",
    "\n",
    "    def read_node_features(self, fpath, nodes, graphs, fn):\n",
    "        node_features_all = self.parse_txt_file(fpath, line_parse_fn=fn)\n",
    "        node_features = {}\n",
    "        for node_id, x in enumerate(node_features_all):\n",
    "            graph_id = nodes[node_id]\n",
    "            if graph_id not in node_features:\n",
    "                node_features[graph_id] = [None] * len(graphs[graph_id])\n",
    "            ind = np.where(graphs[graph_id] == node_id)[0]\n",
    "            assert len(ind) == 1, ind\n",
    "            assert node_features[graph_id][ind[0]] is None, node_features[graph_id][ind[0]]\n",
    "            node_features[graph_id][ind[0]] = x\n",
    "        node_features_lst = [node_features[graph_id] for graph_id in sorted(list(graphs.keys()))]\n",
    "        return node_features_lst\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN layers and models\n",
    "class GraphConv(nn.Module):\n",
    "    '''\n",
    "    Graph Convolution Layer according to (T. Kipf and M. Welling, ICLR 2017)\n",
    "    Additional tricks (power of adjacency matrix and weight self connections) as in the Graph U-Net paper\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                in_features,\n",
    "                out_features,\n",
    "                activation=None,\n",
    "                adj_sq=False,\n",
    "                scale_identity=False):\n",
    "        super(GraphConv, self).__init__()\n",
    "        self.fc = nn.Linear(in_features=in_features, out_features=out_features)\n",
    "        self.adj_sq = adj_sq\n",
    "        self.activation = activation\n",
    "        self.scale_identity = scale_identity\n",
    "            \n",
    "    def laplacian_batch(self, A):\n",
    "        batch, N = A.shape[:2]\n",
    "        if self.adj_sq:\n",
    "            A = torch.bmm(A, A)  # use A^2 to increase graph connectivity\n",
    "        I = torch.eye(N).unsqueeze(0).to(device)\n",
    "        if self.scale_identity:\n",
    "            I = 2 * I  # increase weight of self connections\n",
    "        A_hat = A + I\n",
    "        D_hat = (torch.sum(A_hat, 1) + 1e-5) ** (-0.5)\n",
    "        L = D_hat.view(batch, N, 1) * A_hat * D_hat.view(batch, 1, N)\n",
    "        return L\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, A = data[:2]\n",
    "        x = self.fc(torch.bmm(self.laplacian_batch(A), x))\n",
    "        if self.activation is not None:\n",
    "            x = self.activation(x)\n",
    "        return (x, A)\n",
    "        \n",
    "class GCN(nn.Module):\n",
    "    '''\n",
    "    Baseline Graph Convolutional Network with a stack of Graph Convolution Layers and global pooling over nodes.\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 in_features,\n",
    "                 out_features,\n",
    "                 filters=[64,64,64],\n",
    "                 n_hidden=0,\n",
    "                 dropout=0.2,\n",
    "                 adj_sq=False,\n",
    "                 scale_identity=False):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        # Graph convolution layers\n",
    "        self.gconv = nn.Sequential(*([GraphConv(in_features=in_features if layer == 0 else filters[layer - 1], \n",
    "                                                out_features=f, \n",
    "                                                activation=nn.ReLU(inplace=True),\n",
    "                                                adj_sq=adj_sq,\n",
    "                                                scale_identity=scale_identity) for layer, f in enumerate(filters)]))\n",
    "        \n",
    "        # Fully connected layers\n",
    "        fc = []\n",
    "        if dropout > 0:\n",
    "            fc.append(nn.Dropout(p=dropout))\n",
    "        if n_hidden > 0:\n",
    "            fc.append(nn.Linear(filters[-1], n_hidden))\n",
    "            if dropout > 0:\n",
    "                fc.append(nn.Dropout(p=dropout))\n",
    "            n_last = n_hidden\n",
    "        else:\n",
    "            n_last = filters[-1]\n",
    "        fc.append(nn.Linear(n_last, out_features))       \n",
    "        self.fc = nn.Sequential(*fc)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x = self.gconv(data)[0]\n",
    "        x = torch.max(x, dim=1)[0].squeeze()  # max pooling over nodes\n",
    "        x = self.fc(x)\n",
    "        return x  \n",
    "    \n",
    "class GraphUnet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features,\n",
    "                 out_features,\n",
    "                 filters=[64,64,64],\n",
    "                 n_hidden=0,\n",
    "                 dropout=0.2,\n",
    "                 adj_sq=False,\n",
    "                 scale_identity=False,\n",
    "                 shuffle_nodes=False,\n",
    "                 visualize=False,\n",
    "                 pooling_ratios=[0.8, 0.8]):\n",
    "        super(GraphUnet, self).__init__()\n",
    "\n",
    "        self.shuffle_nodes = shuffle_nodes\n",
    "        self.visualize = visualize\n",
    "        self.pooling_ratios = pooling_ratios\n",
    "        # Graph convolution layers\n",
    "        self.gconv = nn.ModuleList([GraphConv(in_features=in_features if layer == 0 else filters[layer - 1], \n",
    "                                                out_features=f, \n",
    "                                                activation=nn.ReLU(inplace=True),\n",
    "                                               adj_sq=adj_sq,\n",
    "                                               scale_identity=scale_identity) for layer, f in enumerate(filters)])\n",
    "        # Pooling layers\n",
    "        self.proj = []\n",
    "        for layer, f in enumerate(filters[:-1]):\n",
    "            # Initialize projection vectors similar to weight/bias initialization in nn.Linear\n",
    "            fan_in = filters[layer]\n",
    "            p = Parameter(torch.Tensor(fan_in, 1))\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            torch.nn.init.uniform_(p, -bound, bound)\n",
    "            self.proj.append(p)\n",
    "        \n",
    "        # Fully connected layers\n",
    "        fc = []\n",
    "        if dropout > 0:\n",
    "            fc.append(nn.Dropout(p=dropout))\n",
    "        if n_hidden > 0:\n",
    "            fc.append(nn.Linear(filters[-1], n_hidden))\n",
    "            if dropout > 0:\n",
    "                fc.append(nn.Dropout(p=dropout))\n",
    "            n_last = n_hidden\n",
    "        else:\n",
    "            n_last = filters[-1]\n",
    "        fc.append(nn.Linear(n_last, out_features))       \n",
    "        self.fc = nn.Sequential(*fc)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        # [signal, W, signal_support, N_nodes, int(label)]\n",
    "        if self.shuffle_nodes:\n",
    "            N = data[0].shape[1]\n",
    "            idx = torch.randperm(N)\n",
    "            data = (data[0][:, idx], data[1][:, idx][idx, :], data[2][:, idx], data[3])\n",
    "        plot = -1\n",
    "        N_nodes_tmp = -1\n",
    "        for layer, gconv in enumerate(self.gconv):\n",
    "            N_nodes = data[3]\n",
    "            N_nodes_max = N_nodes.max()\n",
    "            #print('layer', layer, N_nodes_max)\n",
    "            #data = (data[0][:, :N_nodes_max], data[1][:, :N_nodes_max, :N_nodes_max], data[2][:, :N_nodes_max], data[3])      \n",
    "            B, N, _ = data[0].shape\n",
    "            if layer < len(self.gconv) - 1 and self.visualize:      \n",
    "                x, W = data[:2]\n",
    "                for b in range(B):\n",
    "                    if (layer == 0 and N_nodes[b] < 20 and N_nodes[b] > 10) or plot > -1:\n",
    "                        if plot > -1 and plot != b:\n",
    "                            continue\n",
    "                        if N_nodes_tmp < 0:\n",
    "                            N_nodes_tmp = N_nodes[b]\n",
    "                        plt.figure(figsize=(18,5))\n",
    "                        plt.subplot(141)\n",
    "                        plt.title('layer %d, Input adjacency matrix' % (layer))\n",
    "                        plt.imshow(W[b][:N_nodes_tmp, :N_nodes_tmp].data.cpu().numpy())\n",
    "                        plot = b                        \n",
    "                        break\n",
    "            mask = data[2].clone()\n",
    "            data = gconv(data)\n",
    "            x, W = data\n",
    "            if layer < len(self.gconv) - 1:\n",
    "                B, N, C = x.shape\n",
    "                y = torch.mm(x.view(B * N, C), self.proj[layer]).view(B, N)\n",
    "                y = y / (torch.sum(self.proj[layer] ** 2).view(1, 1) ** 0.5)  # node scores used for ranking below\n",
    "                idx = torch.sort(y, dim=1)[1]  # B,N                \n",
    "                N_remove = (N_nodes.float() * (1 - self.pooling_ratios[layer])).long()\n",
    "                assert torch.all(N_nodes > N_remove), 'the number of removed nodes must be large than the number of nodes'\n",
    "                for b in range(B):\n",
    "                    assert torch.sum(mask[b]) == float(N_nodes[b]), (torch.sum(mask[b]), N_nodes[b])\n",
    "                N_nodes_prev = N_nodes\n",
    "                N_nodes = N_nodes - N_remove\n",
    "                                \n",
    "                for b in range(B):\n",
    "                    idx_b = idx[b, mask[b, idx[b]] == 1]\n",
    "                    assert len(idx_b) >= N_nodes[b], (len(idx_b), N_nodes[b])\n",
    "                    mask[b, idx_b[:N_remove[b]]] = 0\n",
    "                for b in range(B):\n",
    "                    assert torch.sum(mask[b]) == float(N_nodes[b]), (b, torch.sum(mask[b]), N_nodes[b], N_remove[b], N_nodes_prev[b])\n",
    "                    s = torch.sum(y[b] >= torch.min((y * mask.float())[b]))\n",
    "                    assert s >= float(N_nodes[b]), (s, N_nodes[b], (y * mask.float())[b])\n",
    "                \n",
    "                mask = mask.unsqueeze(2)\n",
    "                x = x * torch.tanh(y).unsqueeze(2) * mask\n",
    "                W = mask * W * mask.view(B, 1, N)\n",
    "                mask = mask.squeeze()\n",
    "                data = (x, W, mask, N_nodes)\n",
    "                \n",
    "                if self.visualize and plot > -1:\n",
    "                    b = plot\n",
    "                    plt.subplot(142)\n",
    "                    plt.title('layer %d, Ranking' % (layer))\n",
    "                    plt.imshow(y[b].view(N, 1).expand(N, 2)[:N_nodes_tmp].data.cpu().numpy())\n",
    "                    plt.colorbar()\n",
    "                    plt.subplot(143)\n",
    "                    plt.title('layer %d, Pooled nodes (%d/%d)' % (layer, mask[b].sum(), N_nodes_prev[b]))\n",
    "                    plt.imshow(mask[b].view(N, 1).expand(N, 2)[:N_nodes_tmp].data.cpu().numpy())\n",
    "                    plt.subplot(144)\n",
    "                    plt.title('layer %d, Pooled adjacency matrix' % (layer))\n",
    "                    plt.imshow(W[b][:N_nodes_tmp, :N_nodes_tmp].data.cpu().numpy())\n",
    "                    plt.show()\n",
    "                        \n",
    "        if self.visualize and plot > -1:\n",
    "            self.visualize = False\n",
    "        x = torch.max(x, dim=1)[0].squeeze()  # max pooling over nodes\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading data')\n",
    "    datareader = DataReader(data_dir='./data/%s/' % dataset.upper(),\n",
    "                            rnd_state=np.random.RandomState(seed),\n",
    "                            folds=n_folds,\n",
    "                            use_cont_node_attr=True)\n",
    "    datareader19 = DataReader(data_dir='./data/%s/' % dataset2.upper(),\n",
    "                            rnd_state=np.random.RandomState(seed),\n",
    "                            folds=n_folds,\n",
    "                            use_cont_node_attr=True)\n",
    "\n",
    "    acc_folds = []\n",
    "    for fold_id in range(n_folds):\n",
    "        print('\\nFOLD', fold_id)\n",
    "        loaders = []\n",
    "        for split in ['train', 'test']:\n",
    "            gdata = GraphDataSiamese(fold_id=fold_id,\n",
    "                              datareader04=datareader, datareader19 = datareader19,\n",
    "                              split=split)\n",
    "\n",
    "            loader = torch.utils.data.DataLoader(gdata,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 shuffle=split.find('train') >= 0,\n",
    "                                                 num_workers=threads)\n",
    "            loaders.append(loader)\n",
    "    \n",
    "    if model_name == 'gcn':\n",
    "        model = GCN(in_features=loaders[0].dataset.features_dim,\n",
    "                    out_features=emb_dim, #loaders[0].dataset.n_classes\n",
    "                    n_hidden=0,\n",
    "                    filters=[64,64,64],\n",
    "                    dropout=0.2,\n",
    "                    adj_sq=False,\n",
    "                    scale_identity=False).to(device)\n",
    "    elif model_name == 'unet':\n",
    "        model = GraphUnet(in_features=loaders[0].dataset.features_dim,\n",
    "                          out_features=loaders[0].dataset.n_classes,\n",
    "                          n_hidden=0,\n",
    "                          filters=[64,64,64],\n",
    "                          dropout=0.2,\n",
    "                          adj_sq=False,\n",
    "                          scale_identity=False,\n",
    "                          shuffle_nodes=shuffle_nodes,\n",
    "                          visualize=visualize).to(device)\n",
    "    else:\n",
    "        raise NotImplementedError(model_name)\n",
    "\n",
    "    print('\\nInitialize model')\n",
    "    print(model)\n",
    "    c = 0\n",
    "    for p in filter(lambda p: p.requires_grad, model.parameters()):\n",
    "        c += p.numel()\n",
    "    print('N trainable parameters:', c)\n",
    "\n",
    "    optimizer = optim.Adam(\n",
    "                filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                lr=lr,\n",
    "                weight_decay=wdecay,\n",
    "                betas=(0.5, 0.999))\n",
    "    \n",
    "\n",
    "    def calculate_features(train_loader):\n",
    "        features2019 = []\n",
    "        features2004 = []\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            for i in range(len(data[0])):\n",
    "                data[0][i] = data[0][i].to(device)\n",
    "                data[1][i] = data[1][i].to(device)\n",
    "            output_2004 = model(data[0])\n",
    "            output_2019 = model(data[1])\n",
    "            features_2004 = output_2004.detach().cpu().max(1, keepdim=True)[1]\n",
    "            features_2019 = output_2004.detach().cpu().max(1, keepdim=True)[1]\n",
    "            features2004.append(features_2004.reshape(features_2004.shape[0], emb_dim))\n",
    "            features2019.append(features_2019.reshape(features_2019.shape[0], emb_dim))\n",
    "        return features2004, features2019\n",
    "\n",
    "    def test(test_loader):\n",
    "        model.eval()\n",
    "        start = time.time()\n",
    "        test_loss, correct, n_samples = 0, 0, 0\n",
    "        for batch_idx, data in enumerate(test_loader):\n",
    "            for i in range(len(data)):\n",
    "                data[i] = data[i].to(device)\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, data[4], reduction='sum')\n",
    "            test_loss += loss.item()\n",
    "            n_samples += len(output)\n",
    "            pred = output.detach().cpu().max(1, keepdim=True)[1]\n",
    "\n",
    "            correct += pred.eq(data[4].detach().cpu().view_as(pred)).sum().item()\n",
    "\n",
    "        time_iter = time.time() - start\n",
    "\n",
    "        test_loss /= n_samples\n",
    "\n",
    "        acc = 100. * correct / n_samples\n",
    "        print('Test set (epoch {}): Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(epoch, \n",
    "                                                                                              test_loss, \n",
    "                                                                                              correct, \n",
    "                                                                                              n_samples, acc))\n",
    "        return acc\n",
    "\n",
    "\n",
    "    for epoch in range(1):\n",
    "        f2004, f2019 = calculate_features(loaders[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "N nodes avg/std/min/max: \t39.06/45.76/4/620\n",
      "N edges avg/std/min/max: \t72.82/84.60/5/1049\n",
      "Node degree avg/std/min/max: \t3.73/1.15/0/25\n",
      "Node features dim: \t\t3\n",
      "N classes: \t\t\t2\n",
      "Classes: \t\t\t[0 1]\n",
      "Class 0: \t\t\t663 samples\n",
      "Class 1: \t\t\t450 samples\n",
      "feature 0, count 21151/43471\n",
      "feature 1, count 20931/43471\n",
      "feature 2, count 1389/43471\n",
      "\n",
      "FOLD 0\n",
      "TRAIN: 1001/1113\n",
      "TEST: 112/1113\n",
      "\n",
      "Initialize model\n",
      "GraphUnet(\n",
      "  (gconv): ModuleList(\n",
      "    (0): GraphConv(\n",
      "      (fc): Linear(in_features=3, out_features=64, bias=True)\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (1): GraphConv(\n",
      "      (fc): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): GraphConv(\n",
      "      (fc): Linear(in_features=64, out_features=64, bias=True)\n",
      "      (activation): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Dropout(p=0.2, inplace=False)\n",
      "    (1): Linear(in_features=64, out_features=2, bias=True)\n",
      "  )\n",
      ")\n",
      "N trainable parameters: 8706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mkhokhlova\\AppData\\Local\\Continuum\\anaconda3\\envs\\graphs37\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:122: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [32/1001 (3%)]\tLoss: 0.693934 (avg: 0.693934) \tsec/iter: 1.6132\n",
      "Train Epoch: 0 [352/1001 (34%)]\tLoss: 0.660553 (avg: 0.682426) \tsec/iter: 0.5552\n",
      "Train Epoch: 0 [672/1001 (66%)]\tLoss: 0.687468 (avg: 0.681145) \tsec/iter: 0.5058\n",
      "Train Epoch: 0 [992/1001 (97%)]\tLoss: 0.713179 (avg: 0.676185) \tsec/iter: 0.4832\n",
      "Train Epoch: 0 [1001/1001 (100%)]\tLoss: 0.726204 (avg: 0.676635) \tsec/iter: 0.4729\n",
      "Test set (epoch 0): Average loss: 0.6610, Accuracy: 597/1001 (59.64%)\n",
      "\n",
      "Train Epoch: 1 [32/1001 (3%)]\tLoss: 0.712230 (avg: 0.712230) \tsec/iter: 0.3820\n",
      "Train Epoch: 1 [352/1001 (34%)]\tLoss: 0.645821 (avg: 0.666679) \tsec/iter: 0.4553\n",
      "Train Epoch: 1 [672/1001 (66%)]\tLoss: 0.702299 (avg: 0.661581) \tsec/iter: 0.4526\n",
      "Train Epoch: 1 [992/1001 (97%)]\tLoss: 0.827227 (avg: 0.655527) \tsec/iter: 0.4502\n",
      "Train Epoch: 1 [1001/1001 (100%)]\tLoss: 0.654195 (avg: 0.655515) \tsec/iter: 0.4410\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-bbbe72f928b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    106\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m         \u001b[0macc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m     \u001b[0macc_folds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0macc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-bbbe72f928b7>\u001b[0m in \u001b[0;36mtest\u001b[1;34m(test_loader)\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m                 \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sum'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\graphs37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-a210588ef4f2>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    153\u001b[0m                         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m             \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgconv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    156\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mW\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    157\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgconv\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\envs\\graphs37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-a210588ef4f2>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlaplacian_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m             \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-a210588ef4f2>\u001b[0m in \u001b[0;36mlaplacian_batch\u001b[1;34m(self, A)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mA_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mA\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mI\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mD_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mA_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1e-5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mL\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mD_hat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mA_hat\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mD_hat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print('Loading data')\n",
    "    datareader = DataReader(data_dir='./data/%s/' % dataset.upper(),\n",
    "                            rnd_state=np.random.RandomState(seed),\n",
    "                            folds=n_folds,\n",
    "                            use_cont_node_attr=True)\n",
    "    datareader19 = DataReader(data_dir='./data/%s/' % dataset2.upper(),\n",
    "                            rnd_state=np.random.RandomState(seed),\n",
    "                            folds=n_folds,\n",
    "                            use_cont_node_attr=True)\n",
    "\n",
    "    acc_folds = []\n",
    "    for fold_id in range(n_folds):\n",
    "        print('\\nFOLD', fold_id)\n",
    "        loaders = []\n",
    "        for split in ['train', 'test']:\n",
    "            gdata = GraphDataSiamese(fold_id=fold_id,\n",
    "                              datareader04=datareader, datareader19 = datareader19,\n",
    "                              split=split)\n",
    "\n",
    "            loader = torch.utils.data.DataLoader(gdata,\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 shuffle=split.find('train') >= 0,\n",
    "                                                 num_workers=threads)\n",
    "            loaders.append(loader)\n",
    "    \n",
    "    if model_name == 'gcn':\n",
    "        model = GCN(in_features=loaders[0].dataset.features_dim,\n",
    "                    out_features=emb_dim, #loaders[0].dataset.n_classes\n",
    "                    n_hidden=0,\n",
    "                    filters=[64,64,64],\n",
    "                    dropout=0.2,\n",
    "                    adj_sq=False,\n",
    "                    scale_identity=False).to(device)\n",
    "    elif model_name == 'unet':\n",
    "        model = GraphUnet(in_features=loaders[0].dataset.features_dim,\n",
    "                          out_features=loaders[0].dataset.n_classes,\n",
    "                          n_hidden=0,\n",
    "                          filters=[64,64,64],\n",
    "                          dropout=0.2,\n",
    "                          adj_sq=False,\n",
    "                          scale_identity=False,\n",
    "                          shuffle_nodes=shuffle_nodes,\n",
    "                          visualize=visualize).to(device)\n",
    "    else:\n",
    "        raise NotImplementedError(model_name)\n",
    "\n",
    "    print('\\nInitialize model')\n",
    "    print(model)\n",
    "    c = 0\n",
    "    for p in filter(lambda p: p.requires_grad, model.parameters()):\n",
    "        c += p.numel()\n",
    "    print('N trainable parameters:', c)\n",
    "\n",
    "    optimizer = optim.Adam(\n",
    "                filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                lr=lr,\n",
    "                weight_decay=wdecay,\n",
    "                betas=(0.5, 0.999))\n",
    "    \n",
    "    scheduler = lr_scheduler.MultiStepLR(optimizer, [20, 30], gamma=0.1)\n",
    "\n",
    "    def train(train_loader):\n",
    "        scheduler.step()\n",
    "        model.train()\n",
    "        start = time.time()\n",
    "        train_loss, n_samples = 0, 0\n",
    "        for batch_idx, data in enumerate(train_loader):\n",
    "            for i in range(len(data)):\n",
    "                data[i] = data[i].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, data[4])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            time_iter = time.time() - start\n",
    "            train_loss += loss.item() * len(output)\n",
    "            n_samples += len(output)\n",
    "            if batch_idx % log_interval == 0 or batch_idx == len(train_loader) - 1:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f} (avg: {:.6f}) \\tsec/iter: {:.4f}'.format(\n",
    "                    epoch, n_samples, len(train_loader.dataset),\n",
    "                    100. * (batch_idx + 1) / len(train_loader), loss.item(), train_loss / n_samples, time_iter / (batch_idx + 1) ))\n",
    "    #             break \n",
    "    def test(test_loader):\n",
    "        model.eval()\n",
    "        start = time.time()\n",
    "        test_loss, correct, n_samples = 0, 0, 0\n",
    "        for batch_idx, data in enumerate(test_loader):\n",
    "            for i in range(len(data)):\n",
    "                data[i] = data[i].to(device)\n",
    "            output = model(data)\n",
    "            loss = loss_fn(output, data[4], reduction='sum')\n",
    "            test_loss += loss.item()\n",
    "            n_samples += len(output)\n",
    "            pred = output.detach().cpu().max(1, keepdim=True)[1]\n",
    "\n",
    "            correct += pred.eq(data[4].detach().cpu().view_as(pred)).sum().item()\n",
    "\n",
    "        time_iter = time.time() - start\n",
    "\n",
    "        test_loss /= n_samples\n",
    "\n",
    "        acc = 100. * correct / n_samples\n",
    "        print('Test set (epoch {}): Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(epoch, \n",
    "                                                                                              test_loss, \n",
    "                                                                                              correct, \n",
    "                                                                                              n_samples, acc))\n",
    "        return acc\n",
    "\n",
    "    loss_fn = F.cross_entropy\n",
    "    for epoch in range(epochs):\n",
    "        train(loaders[0])\n",
    "        acc = test(loaders[0])\n",
    "    acc_folds.append(acc)\n",
    "\n",
    "print(acc_folds)\n",
    "print('{}-fold cross validation avg acc (+- std): {} ({})'.format(n_folds, np.mean(acc_folds), np.std(acc_folds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
